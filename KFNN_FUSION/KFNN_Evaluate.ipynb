{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division, absolute_import\n",
    "import argparse\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append('.')\n",
    "import pretrainedmodels\n",
    "import pretrainedmodels.utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'model_best.pth.tar')\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    lr = args.lr * (0.1 ** (epoch // 30))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, a1, model_1, a2, model_2, criterion):\n",
    "    with torch.no_grad():\n",
    "        batch_time = AverageMeter()\n",
    "        losses = AverageMeter()\n",
    "        top1 = AverageMeter()\n",
    "        top5 = AverageMeter()\n",
    "\n",
    "        # switch to evaluate mode\n",
    "        model_1.eval()\n",
    "        model_2.eval()\n",
    "\n",
    "        end = time.time()\n",
    "        for i, (input, target) in enumerate(val_loader):\n",
    "            target = target.cuda()\n",
    "            input = input.cuda()\n",
    "\n",
    "            # compute output\n",
    "            output_1 = model_1(input)\n",
    "            output_2 = model_2(input)\n",
    "            loss_1 = criterion(output_1, target)\n",
    "            loss_2 = criterion(output_2, target)\n",
    "            \n",
    "            # fuse\n",
    "            output = a1 * output_1 + a2 * output_2\n",
    "            \n",
    "            # measure accuracy and record loss\n",
    "            prec1, prec5 = accuracy(output.data, target.data, topk=(1, 5))\n",
    "            loss = a1 * loss_1 + a2 * loss_2 \n",
    "            losses.update(loss.data.item(), input.size(0))\n",
    "            top1.update(prec1.item(), input.size(0))\n",
    "            top5.update(prec5.item(), input.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % 10 == 0:\n",
    "                print('Test: [{0}/{1}]\\t'\n",
    "                      'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                      'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                      'Acc@1 {top1.val:.3f} ({top1.avg:.3f})\\t'\n",
    "                      'Acc@5 {top5.val:.3f} ({top5.avg:.3f})'.format(\n",
    "                       i, len(val_loader), batch_time=batch_time, loss=losses,\n",
    "                       top1=top1, top5=top5))\n",
    "\n",
    "        print(' * Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}'\n",
    "              .format(top1=top1, top5=top5))\n",
    "\n",
    "        return top1.avg, top5.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=> using pre-trained parameters '{}'\".format('imagenet'))\n",
    "a1 = 0.5002\n",
    "model_1 = pretrainedmodels.__dict__['resnet18'](num_classes=1000,pretrained='imagenet')\n",
    "a2 = 0.4998\n",
    "model_2 = pretrainedmodels.__dict__['vgg11'](num_classes=1000,pretrained='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cudnn.benchmark = True\n",
    "data_path ='/media/k1407/DA18EBFA09C1B27D/ImageNet/imagenet2012'\n",
    "valdir = os.path.join(data_path, 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = 0.875\n",
    "\n",
    "print('Images transformed from size {} to {}'.format(\n",
    "    int(round(max(model_1.input_size) / scale)),\n",
    "    model_1.input_size))\n",
    "\n",
    "val_tf = pretrainedmodels.utils.TransformImage(\n",
    "    model_1,\n",
    "    scale=scale,\n",
    "    preserve_aspect_ratio=True\n",
    ")\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    datasets.ImageFolder(valdir, val_tf),\n",
    "    batch_size=20, shuffle=False,\n",
    "    num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "model_1 = torch.nn.DataParallel(model_1).cuda()\n",
    "model_2 = torch.nn.DataParallel(model_2).cuda()\n",
    "validate(val_loader, a1, model_1, a2, model_2, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = 0.5042\n",
    "a2 = 0.4958\n",
    "validate(val_loader, a1, model_1, a2, model_2, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "validate(val_loader, a1, model_1, a2, model_2, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_2(val_loader_1, val_loader_2, a1, model_1, a2, model_2, criterion):\n",
    "    with torch.no_grad():\n",
    "        batch_time = AverageMeter()\n",
    "        losses = AverageMeter()\n",
    "        top1 = AverageMeter()\n",
    "        top5 = AverageMeter()\n",
    "\n",
    "        # switch to evaluate mode\n",
    "        model_1.eval()\n",
    "        model_2.eval()\n",
    "\n",
    "        end = time.time()\n",
    "        for i, data in enumerate(zip(val_loader_1, val_loader_2)):\n",
    "            inputs1 = data[0][0].cuda();\n",
    "            labels1 = data[0][1].cuda();\n",
    "            inputs2 = data[1][0].cuda();\n",
    "            labels2 = data[1][1].cuda();\n",
    "            \n",
    "            # compute output\n",
    "            output_1 = model_1(inputs1)\n",
    "            output_2 = model_2(inputs2)\n",
    "            loss_1 = criterion(output_1, labels1)\n",
    "            loss_2 = criterion(output_2, labels2)\n",
    "            \n",
    "            # fuse\n",
    "            output = a1 * output_1 + a2 * output_2\n",
    "            \n",
    "            # measure accuracy and record loss\n",
    "            prec1, prec5 = accuracy(output.data, labels1.data, topk=(1, 5))\n",
    "            loss = a1 * loss_1 + a2 * loss_2 \n",
    "            losses.update(loss.data.item(), inputs1.size(0))\n",
    "            top1.update(prec1.item(), inputs1.size(0))\n",
    "            top5.update(prec5.item(), inputs1.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % 10 == 0:\n",
    "                print('Test: [{0}/{1}]\\t'\n",
    "                      'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                      'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                      'Acc@1 {top1.val:.3f} ({top1.avg:.3f})\\t'\n",
    "                      'Acc@5 {top5.val:.3f} ({top5.avg:.3f})'.format(\n",
    "                       i, len(val_loader_1), batch_time=batch_time, loss=losses,\n",
    "                       top1=top1, top5=top5))\n",
    "\n",
    "        print(' * Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}'\n",
    "              .format(top1=top1, top5=top5))\n",
    "\n",
    "        return top1.avg, top5.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> using pre-trained parameters 'imagenet'\n",
      "Images transformed from size 256 to [3, 224, 224]\n",
      "Test: [0/2500]\tTime 1.774 (1.774)\tLoss 0.9383 (0.9383)\tAcc@1 80.000 (80.000)\tAcc@5 95.000 (95.000)\n",
      "Test: [10/2500]\tTime 0.143 (0.401)\tLoss 0.5216 (0.6229)\tAcc@1 95.000 (85.000)\tAcc@5 100.000 (96.818)\n",
      "Test: [20/2500]\tTime 0.970 (0.383)\tLoss 0.9386 (0.7610)\tAcc@1 90.000 (82.619)\tAcc@5 95.000 (95.714)\n",
      "Test: [30/2500]\tTime 0.144 (0.343)\tLoss 0.3470 (0.6000)\tAcc@1 90.000 (85.484)\tAcc@5 100.000 (96.935)\n",
      "Test: [40/2500]\tTime 0.922 (0.338)\tLoss 0.6895 (0.5053)\tAcc@1 85.000 (87.683)\tAcc@5 90.000 (97.317)\n",
      "Test: [50/2500]\tTime 0.142 (0.321)\tLoss 0.4646 (0.4816)\tAcc@1 90.000 (88.333)\tAcc@5 95.000 (97.255)\n",
      "Test: [60/2500]\tTime 0.941 (0.323)\tLoss 0.4621 (0.4844)\tAcc@1 95.000 (88.689)\tAcc@5 95.000 (97.377)\n",
      "Test: [70/2500]\tTime 0.145 (0.315)\tLoss 0.2571 (0.5090)\tAcc@1 95.000 (88.028)\tAcc@5 100.000 (97.324)\n",
      "Test: [80/2500]\tTime 0.730 (0.313)\tLoss 2.2027 (0.5449)\tAcc@1 45.000 (87.346)\tAcc@5 90.000 (97.037)\n",
      "Test: [90/2500]\tTime 0.143 (0.310)\tLoss 1.7474 (0.6467)\tAcc@1 45.000 (84.615)\tAcc@5 95.000 (96.319)\n",
      "Test: [100/2500]\tTime 1.010 (0.317)\tLoss 0.5446 (0.6537)\tAcc@1 85.000 (84.059)\tAcc@5 100.000 (96.485)\n",
      "Test: [110/2500]\tTime 0.144 (0.311)\tLoss 1.1798 (0.6603)\tAcc@1 80.000 (83.964)\tAcc@5 90.000 (96.486)\n",
      "Test: [120/2500]\tTime 0.847 (0.312)\tLoss 0.4734 (0.7114)\tAcc@1 90.000 (82.810)\tAcc@5 100.000 (96.074)\n",
      "Test: [130/2500]\tTime 0.142 (0.307)\tLoss 0.3175 (0.7074)\tAcc@1 95.000 (83.130)\tAcc@5 100.000 (96.031)\n",
      "Test: [140/2500]\tTime 0.840 (0.311)\tLoss 0.9063 (0.7445)\tAcc@1 85.000 (82.234)\tAcc@5 95.000 (95.887)\n",
      "Test: [150/2500]\tTime 0.142 (0.310)\tLoss 2.8297 (0.7729)\tAcc@1 35.000 (81.689)\tAcc@5 85.000 (95.596)\n",
      "Test: [160/2500]\tTime 0.781 (0.310)\tLoss 1.3267 (0.8053)\tAcc@1 65.000 (80.621)\tAcc@5 90.000 (95.373)\n",
      "Test: [170/2500]\tTime 0.146 (0.308)\tLoss 1.1625 (0.8291)\tAcc@1 65.000 (79.737)\tAcc@5 90.000 (95.234)\n",
      "Test: [180/2500]\tTime 0.162 (0.307)\tLoss 0.3610 (0.8181)\tAcc@1 100.000 (80.221)\tAcc@5 100.000 (95.193)\n",
      "Test: [190/2500]\tTime 0.143 (0.305)\tLoss 0.3469 (0.8300)\tAcc@1 85.000 (79.660)\tAcc@5 100.000 (95.262)\n",
      "Test: [200/2500]\tTime 0.806 (0.308)\tLoss 0.2179 (0.8343)\tAcc@1 95.000 (79.876)\tAcc@5 100.000 (95.174)\n",
      "Test: [210/2500]\tTime 0.142 (0.305)\tLoss 0.4692 (0.8159)\tAcc@1 90.000 (80.261)\tAcc@5 95.000 (95.308)\n",
      "Test: [220/2500]\tTime 0.352 (0.305)\tLoss 0.4873 (0.8037)\tAcc@1 95.000 (80.701)\tAcc@5 95.000 (95.362)\n",
      "Test: [230/2500]\tTime 0.142 (0.304)\tLoss 0.0205 (0.7813)\tAcc@1 100.000 (81.277)\tAcc@5 100.000 (95.498)\n",
      "Test: [240/2500]\tTime 0.894 (0.304)\tLoss 0.1002 (0.7624)\tAcc@1 95.000 (81.846)\tAcc@5 100.000 (95.581)\n",
      "Test: [250/2500]\tTime 0.142 (0.300)\tLoss 0.0008 (0.7525)\tAcc@1 100.000 (82.072)\tAcc@5 100.000 (95.637)\n",
      "Test: [260/2500]\tTime 0.979 (0.304)\tLoss 0.2880 (0.7476)\tAcc@1 95.000 (82.203)\tAcc@5 100.000 (95.670)\n",
      "Test: [270/2500]\tTime 0.141 (0.303)\tLoss 1.7711 (0.7577)\tAcc@1 60.000 (82.232)\tAcc@5 80.000 (95.480)\n",
      "Test: [280/2500]\tTime 0.946 (0.307)\tLoss 1.4196 (0.7564)\tAcc@1 65.000 (82.260)\tAcc@5 80.000 (95.480)\n",
      "Test: [290/2500]\tTime 0.141 (0.305)\tLoss 0.5505 (0.7582)\tAcc@1 90.000 (82.285)\tAcc@5 100.000 (95.464)\n",
      "Test: [300/2500]\tTime 0.478 (0.304)\tLoss 0.9751 (0.7688)\tAcc@1 75.000 (82.159)\tAcc@5 90.000 (95.399)\n",
      "Test: [310/2500]\tTime 0.144 (0.303)\tLoss 1.6639 (0.7750)\tAcc@1 60.000 (81.945)\tAcc@5 90.000 (95.354)\n",
      "Test: [320/2500]\tTime 0.503 (0.303)\tLoss 0.5680 (0.7840)\tAcc@1 85.000 (81.854)\tAcc@5 95.000 (95.234)\n",
      "Test: [330/2500]\tTime 0.144 (0.303)\tLoss 0.3769 (0.7683)\tAcc@1 95.000 (82.221)\tAcc@5 95.000 (95.332)\n",
      "Test: [340/2500]\tTime 1.086 (0.306)\tLoss 0.0593 (0.7579)\tAcc@1 100.000 (82.434)\tAcc@5 100.000 (95.425)\n",
      "Test: [350/2500]\tTime 0.143 (0.305)\tLoss 0.5034 (0.7441)\tAcc@1 80.000 (82.707)\tAcc@5 100.000 (95.499)\n",
      "Test: [360/2500]\tTime 0.343 (0.304)\tLoss 0.1519 (0.7349)\tAcc@1 95.000 (82.936)\tAcc@5 100.000 (95.554)\n",
      "Test: [370/2500]\tTime 0.146 (0.303)\tLoss 0.1757 (0.7256)\tAcc@1 100.000 (83.181)\tAcc@5 100.000 (95.620)\n",
      "Test: [380/2500]\tTime 0.915 (0.304)\tLoss 0.9452 (0.7265)\tAcc@1 75.000 (83.136)\tAcc@5 100.000 (95.577)\n",
      "Test: [390/2500]\tTime 0.143 (0.302)\tLoss 0.1493 (0.7269)\tAcc@1 95.000 (83.120)\tAcc@5 100.000 (95.601)\n",
      "Test: [400/2500]\tTime 0.432 (0.302)\tLoss 0.3495 (0.7263)\tAcc@1 90.000 (83.042)\tAcc@5 100.000 (95.673)\n",
      "Test: [410/2500]\tTime 0.144 (0.301)\tLoss 0.1446 (0.7335)\tAcc@1 100.000 (82.908)\tAcc@5 100.000 (95.584)\n",
      "Test: [420/2500]\tTime 0.853 (0.302)\tLoss 0.8262 (0.7513)\tAcc@1 80.000 (82.268)\tAcc@5 95.000 (95.523)\n",
      "Test: [430/2500]\tTime 0.143 (0.301)\tLoss 0.9028 (0.7569)\tAcc@1 75.000 (82.181)\tAcc@5 95.000 (95.510)\n",
      "Test: [440/2500]\tTime 0.821 (0.302)\tLoss 0.7579 (0.7631)\tAcc@1 85.000 (81.984)\tAcc@5 100.000 (95.556)\n",
      "Test: [450/2500]\tTime 0.144 (0.301)\tLoss 0.9911 (0.7613)\tAcc@1 65.000 (81.940)\tAcc@5 100.000 (95.599)\n",
      "Test: [460/2500]\tTime 0.558 (0.299)\tLoss 1.0500 (0.7605)\tAcc@1 70.000 (81.909)\tAcc@5 90.000 (95.618)\n",
      "Test: [470/2500]\tTime 0.142 (0.298)\tLoss 0.5420 (0.7677)\tAcc@1 80.000 (81.656)\tAcc@5 100.000 (95.626)\n",
      "Test: [480/2500]\tTime 0.512 (0.298)\tLoss 0.8287 (0.7702)\tAcc@1 85.000 (81.590)\tAcc@5 100.000 (95.624)\n",
      "Test: [490/2500]\tTime 0.145 (0.297)\tLoss 1.0870 (0.7731)\tAcc@1 75.000 (81.548)\tAcc@5 90.000 (95.591)\n",
      "Test: [500/2500]\tTime 0.621 (0.297)\tLoss 1.1897 (0.7739)\tAcc@1 80.000 (81.527)\tAcc@5 100.000 (95.639)\n",
      "Test: [510/2500]\tTime 0.145 (0.296)\tLoss 0.7305 (0.7733)\tAcc@1 85.000 (81.458)\tAcc@5 100.000 (95.656)\n",
      "Test: [520/2500]\tTime 0.674 (0.296)\tLoss 0.2628 (0.7723)\tAcc@1 100.000 (81.430)\tAcc@5 100.000 (95.672)\n",
      "Test: [530/2500]\tTime 0.142 (0.295)\tLoss 0.5412 (0.7723)\tAcc@1 75.000 (81.412)\tAcc@5 100.000 (95.669)\n",
      "Test: [540/2500]\tTime 0.594 (0.294)\tLoss 0.4384 (0.7704)\tAcc@1 95.000 (81.460)\tAcc@5 100.000 (95.675)\n",
      "Test: [550/2500]\tTime 0.145 (0.293)\tLoss 1.1703 (0.7668)\tAcc@1 80.000 (81.552)\tAcc@5 95.000 (95.726)\n",
      "Test: [560/2500]\tTime 0.487 (0.294)\tLoss 0.5634 (0.7702)\tAcc@1 90.000 (81.515)\tAcc@5 95.000 (95.704)\n",
      "Test: [570/2500]\tTime 0.145 (0.293)\tLoss 0.9202 (0.7762)\tAcc@1 85.000 (81.436)\tAcc@5 90.000 (95.674)\n",
      "Test: [580/2500]\tTime 0.405 (0.293)\tLoss 0.5510 (0.7746)\tAcc@1 90.000 (81.386)\tAcc@5 95.000 (95.671)\n",
      "Test: [590/2500]\tTime 0.144 (0.292)\tLoss 0.8135 (0.7747)\tAcc@1 80.000 (81.413)\tAcc@5 90.000 (95.677)\n",
      "Test: [600/2500]\tTime 0.579 (0.292)\tLoss 1.3933 (0.7773)\tAcc@1 45.000 (81.290)\tAcc@5 100.000 (95.682)\n",
      "Test: [610/2500]\tTime 0.144 (0.290)\tLoss 0.0368 (0.7789)\tAcc@1 100.000 (81.113)\tAcc@5 100.000 (95.704)\n",
      "Test: [620/2500]\tTime 0.379 (0.290)\tLoss 1.7007 (0.7785)\tAcc@1 60.000 (81.079)\tAcc@5 95.000 (95.709)\n",
      "Test: [630/2500]\tTime 0.143 (0.289)\tLoss 0.5802 (0.7796)\tAcc@1 90.000 (80.919)\tAcc@5 90.000 (95.729)\n",
      "Test: [640/2500]\tTime 0.868 (0.290)\tLoss 0.5698 (0.7728)\tAcc@1 80.000 (81.108)\tAcc@5 100.000 (95.780)\n",
      "Test: [650/2500]\tTime 0.142 (0.289)\tLoss 0.3795 (0.7673)\tAcc@1 90.000 (81.267)\tAcc@5 100.000 (95.822)\n",
      "Test: [660/2500]\tTime 0.810 (0.290)\tLoss 0.7696 (0.7631)\tAcc@1 75.000 (81.392)\tAcc@5 100.000 (95.847)\n",
      "Test: [670/2500]\tTime 0.144 (0.290)\tLoss 0.4571 (0.7652)\tAcc@1 85.000 (81.230)\tAcc@5 100.000 (95.849)\n",
      "Test: [680/2500]\tTime 0.515 (0.291)\tLoss 3.2727 (0.7703)\tAcc@1 50.000 (81.160)\tAcc@5 90.000 (95.837)\n",
      "Test: [690/2500]\tTime 0.143 (0.290)\tLoss 0.2810 (0.7689)\tAcc@1 95.000 (81.252)\tAcc@5 100.000 (95.818)\n",
      "Test: [700/2500]\tTime 0.775 (0.290)\tLoss 1.1755 (0.7697)\tAcc@1 65.000 (81.170)\tAcc@5 100.000 (95.835)\n",
      "Test: [710/2500]\tTime 0.760 (0.290)\tLoss 0.0644 (0.7748)\tAcc@1 100.000 (80.921)\tAcc@5 100.000 (95.809)\n",
      "Test: [720/2500]\tTime 0.144 (0.290)\tLoss 1.0447 (0.7799)\tAcc@1 80.000 (80.874)\tAcc@5 100.000 (95.749)\n",
      "Test: [730/2500]\tTime 0.464 (0.289)\tLoss 0.9443 (0.7775)\tAcc@1 90.000 (80.958)\tAcc@5 95.000 (95.773)\n",
      "Test: [740/2500]\tTime 0.145 (0.290)\tLoss 0.6058 (0.7718)\tAcc@1 95.000 (81.127)\tAcc@5 95.000 (95.816)\n",
      "Test: [750/2500]\tTime 0.477 (0.289)\tLoss 0.2146 (0.7738)\tAcc@1 95.000 (81.158)\tAcc@5 95.000 (95.799)\n",
      "Test: [760/2500]\tTime 0.142 (0.288)\tLoss 1.3435 (0.7759)\tAcc@1 60.000 (81.097)\tAcc@5 100.000 (95.815)\n",
      "Test: [770/2500]\tTime 0.826 (0.289)\tLoss 0.7229 (0.7733)\tAcc@1 85.000 (81.167)\tAcc@5 95.000 (95.843)\n",
      "Test: [780/2500]\tTime 0.145 (0.289)\tLoss 1.3655 (0.7787)\tAcc@1 50.000 (81.069)\tAcc@5 95.000 (95.787)\n",
      "Test: [790/2500]\tTime 0.627 (0.289)\tLoss 0.2711 (0.7829)\tAcc@1 95.000 (80.967)\tAcc@5 100.000 (95.771)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [800/2500]\tTime 0.146 (0.289)\tLoss 0.2328 (0.7808)\tAcc@1 95.000 (81.061)\tAcc@5 100.000 (95.811)\n",
      "Test: [810/2500]\tTime 0.691 (0.288)\tLoss 0.4184 (0.7751)\tAcc@1 90.000 (81.196)\tAcc@5 100.000 (95.845)\n",
      "Test: [820/2500]\tTime 0.142 (0.289)\tLoss 0.5322 (0.7713)\tAcc@1 90.000 (81.340)\tAcc@5 90.000 (95.859)\n",
      "Test: [830/2500]\tTime 0.404 (0.289)\tLoss 0.1995 (0.7716)\tAcc@1 95.000 (81.312)\tAcc@5 100.000 (95.854)\n",
      "Test: [840/2500]\tTime 0.143 (0.288)\tLoss 0.6210 (0.7671)\tAcc@1 90.000 (81.439)\tAcc@5 90.000 (95.868)\n",
      "Test: [850/2500]\tTime 0.453 (0.288)\tLoss 0.0721 (0.7653)\tAcc@1 100.000 (81.528)\tAcc@5 100.000 (95.881)\n",
      "Test: [860/2500]\tTime 0.145 (0.287)\tLoss 0.4952 (0.7657)\tAcc@1 95.000 (81.539)\tAcc@5 100.000 (95.889)\n",
      "Test: [870/2500]\tTime 0.271 (0.287)\tLoss 0.7739 (0.7648)\tAcc@1 45.000 (81.521)\tAcc@5 100.000 (95.901)\n",
      "Test: [880/2500]\tTime 0.143 (0.286)\tLoss 0.4767 (0.7611)\tAcc@1 95.000 (81.561)\tAcc@5 100.000 (95.948)\n",
      "Test: [890/2500]\tTime 0.686 (0.287)\tLoss 1.5587 (0.7611)\tAcc@1 55.000 (81.538)\tAcc@5 95.000 (95.948)\n",
      "Test: [900/2500]\tTime 0.145 (0.286)\tLoss 0.8483 (0.7681)\tAcc@1 85.000 (81.360)\tAcc@5 95.000 (95.932)\n",
      "Test: [910/2500]\tTime 0.424 (0.287)\tLoss 0.0524 (0.7662)\tAcc@1 100.000 (81.449)\tAcc@5 100.000 (95.922)\n",
      "Test: [920/2500]\tTime 0.143 (0.286)\tLoss 0.9100 (0.7648)\tAcc@1 80.000 (81.509)\tAcc@5 95.000 (95.928)\n",
      "Test: [930/2500]\tTime 0.578 (0.286)\tLoss 0.3042 (0.7684)\tAcc@1 95.000 (81.461)\tAcc@5 100.000 (95.929)\n",
      "Test: [940/2500]\tTime 0.145 (0.286)\tLoss 0.0817 (0.7697)\tAcc@1 95.000 (81.440)\tAcc@5 100.000 (95.882)\n",
      "Test: [950/2500]\tTime 0.586 (0.285)\tLoss 1.1154 (0.7703)\tAcc@1 50.000 (81.430)\tAcc@5 95.000 (95.857)\n",
      "Test: [960/2500]\tTime 0.145 (0.285)\tLoss 0.6726 (0.7746)\tAcc@1 80.000 (81.306)\tAcc@5 90.000 (95.827)\n",
      "Test: [970/2500]\tTime 0.452 (0.285)\tLoss 0.0287 (0.7743)\tAcc@1 100.000 (81.287)\tAcc@5 100.000 (95.834)\n",
      "Test: [980/2500]\tTime 0.144 (0.284)\tLoss 0.3992 (0.7755)\tAcc@1 95.000 (81.295)\tAcc@5 95.000 (95.800)\n",
      "Test: [990/2500]\tTime 0.838 (0.285)\tLoss 0.5745 (0.7750)\tAcc@1 90.000 (81.312)\tAcc@5 90.000 (95.787)\n",
      "Test: [1000/2500]\tTime 0.145 (0.284)\tLoss 1.1168 (0.7758)\tAcc@1 40.000 (81.324)\tAcc@5 100.000 (95.789)\n",
      "Test: [1010/2500]\tTime 0.705 (0.284)\tLoss 0.2949 (0.7793)\tAcc@1 95.000 (81.236)\tAcc@5 100.000 (95.752)\n",
      "Test: [1020/2500]\tTime 0.145 (0.284)\tLoss 0.9506 (0.7797)\tAcc@1 75.000 (81.234)\tAcc@5 95.000 (95.730)\n",
      "Test: [1030/2500]\tTime 0.648 (0.285)\tLoss 1.7336 (0.7821)\tAcc@1 65.000 (81.135)\tAcc@5 90.000 (95.718)\n",
      "Test: [1040/2500]\tTime 0.143 (0.284)\tLoss 0.3548 (0.7964)\tAcc@1 90.000 (80.836)\tAcc@5 100.000 (95.581)\n",
      "Test: [1050/2500]\tTime 0.447 (0.284)\tLoss 0.3658 (0.7997)\tAcc@1 90.000 (80.761)\tAcc@5 100.000 (95.580)\n",
      "Test: [1060/2500]\tTime 0.144 (0.283)\tLoss 1.5712 (0.8029)\tAcc@1 75.000 (80.669)\tAcc@5 85.000 (95.566)\n",
      "Test: [1070/2500]\tTime 0.500 (0.283)\tLoss 1.7254 (0.8048)\tAcc@1 70.000 (80.635)\tAcc@5 80.000 (95.537)\n",
      "Test: [1080/2500]\tTime 0.143 (0.283)\tLoss 0.8257 (0.8047)\tAcc@1 85.000 (80.638)\tAcc@5 95.000 (95.537)\n",
      "Test: [1090/2500]\tTime 0.420 (0.282)\tLoss 1.5236 (0.8106)\tAcc@1 70.000 (80.504)\tAcc@5 90.000 (95.481)\n",
      "Test: [1100/2500]\tTime 0.145 (0.282)\tLoss 1.3969 (0.8160)\tAcc@1 60.000 (80.404)\tAcc@5 90.000 (95.431)\n",
      "Test: [1110/2500]\tTime 0.542 (0.282)\tLoss 0.5178 (0.8191)\tAcc@1 80.000 (80.324)\tAcc@5 95.000 (95.405)\n",
      "Test: [1120/2500]\tTime 0.142 (0.282)\tLoss 0.6789 (0.8245)\tAcc@1 90.000 (80.232)\tAcc@5 95.000 (95.352)\n",
      "Test: [1130/2500]\tTime 0.432 (0.282)\tLoss 1.3757 (0.8239)\tAcc@1 80.000 (80.265)\tAcc@5 85.000 (95.332)\n",
      "Test: [1140/2500]\tTime 0.145 (0.281)\tLoss 1.9100 (0.8301)\tAcc@1 65.000 (80.140)\tAcc@5 75.000 (95.259)\n",
      "Test: [1150/2500]\tTime 0.148 (0.281)\tLoss 1.3651 (0.8335)\tAcc@1 60.000 (80.087)\tAcc@5 85.000 (95.200)\n",
      "Test: [1160/2500]\tTime 0.145 (0.281)\tLoss 2.7516 (0.8430)\tAcc@1 55.000 (79.892)\tAcc@5 75.000 (95.138)\n",
      "Test: [1170/2500]\tTime 0.149 (0.281)\tLoss 1.3124 (0.8474)\tAcc@1 65.000 (79.795)\tAcc@5 90.000 (95.077)\n",
      "Test: [1180/2500]\tTime 0.531 (0.281)\tLoss 0.1153 (0.8521)\tAcc@1 95.000 (79.721)\tAcc@5 100.000 (95.030)\n",
      "Test: [1190/2500]\tTime 0.145 (0.281)\tLoss 0.1359 (0.8528)\tAcc@1 100.000 (79.765)\tAcc@5 100.000 (95.004)\n",
      "Test: [1200/2500]\tTime 0.144 (0.280)\tLoss 0.8475 (0.8614)\tAcc@1 80.000 (79.629)\tAcc@5 95.000 (94.913)\n",
      "Test: [1210/2500]\tTime 0.145 (0.280)\tLoss 0.5654 (0.8650)\tAcc@1 75.000 (79.480)\tAcc@5 100.000 (94.889)\n",
      "Test: [1220/2500]\tTime 0.459 (0.280)\tLoss 1.9994 (0.8685)\tAcc@1 35.000 (79.365)\tAcc@5 95.000 (94.865)\n",
      "Test: [1230/2500]\tTime 0.146 (0.280)\tLoss 1.7934 (0.8753)\tAcc@1 60.000 (79.269)\tAcc@5 80.000 (94.797)\n",
      "Test: [1240/2500]\tTime 0.332 (0.280)\tLoss 0.5410 (0.8814)\tAcc@1 90.000 (79.146)\tAcc@5 90.000 (94.710)\n",
      "Test: [1250/2500]\tTime 0.148 (0.281)\tLoss 0.1557 (0.8869)\tAcc@1 95.000 (79.041)\tAcc@5 100.000 (94.624)\n",
      "Test: [1260/2500]\tTime 0.143 (0.281)\tLoss 2.1143 (0.8955)\tAcc@1 50.000 (78.866)\tAcc@5 85.000 (94.528)\n",
      "Test: [1270/2500]\tTime 0.144 (0.281)\tLoss 1.3681 (0.9018)\tAcc@1 75.000 (78.761)\tAcc@5 85.000 (94.469)\n",
      "Test: [1280/2500]\tTime 0.144 (0.281)\tLoss 0.9416 (0.9021)\tAcc@1 75.000 (78.720)\tAcc@5 95.000 (94.469)\n",
      "Test: [1290/2500]\tTime 0.838 (0.281)\tLoss 2.3723 (0.9057)\tAcc@1 35.000 (78.625)\tAcc@5 85.000 (94.435)\n",
      "Test: [1300/2500]\tTime 0.143 (0.281)\tLoss 0.4756 (0.9087)\tAcc@1 85.000 (78.520)\tAcc@5 100.000 (94.400)\n",
      "Test: [1310/2500]\tTime 0.535 (0.282)\tLoss 0.9443 (0.9113)\tAcc@1 75.000 (78.448)\tAcc@5 100.000 (94.359)\n",
      "Test: [1320/2500]\tTime 0.144 (0.282)\tLoss 0.8943 (0.9151)\tAcc@1 80.000 (78.312)\tAcc@5 90.000 (94.349)\n",
      "Test: [1330/2500]\tTime 0.355 (0.282)\tLoss 1.2347 (0.9199)\tAcc@1 70.000 (78.249)\tAcc@5 90.000 (94.290)\n",
      "Test: [1340/2500]\tTime 0.143 (0.282)\tLoss 1.9738 (0.9204)\tAcc@1 60.000 (78.251)\tAcc@5 85.000 (94.254)\n",
      "Test: [1350/2500]\tTime 0.459 (0.282)\tLoss 0.8834 (0.9230)\tAcc@1 75.000 (78.198)\tAcc@5 85.000 (94.238)\n",
      "Test: [1360/2500]\tTime 0.145 (0.281)\tLoss 0.8363 (0.9270)\tAcc@1 75.000 (78.090)\tAcc@5 90.000 (94.192)\n",
      "Test: [1370/2500]\tTime 0.916 (0.282)\tLoss 0.1710 (0.9261)\tAcc@1 95.000 (78.122)\tAcc@5 100.000 (94.190)\n",
      "Test: [1380/2500]\tTime 0.144 (0.282)\tLoss 0.2515 (0.9284)\tAcc@1 95.000 (78.092)\tAcc@5 100.000 (94.160)\n",
      "Test: [1390/2500]\tTime 0.881 (0.282)\tLoss 1.6103 (0.9275)\tAcc@1 70.000 (78.134)\tAcc@5 90.000 (94.159)\n",
      "Test: [1400/2500]\tTime 0.143 (0.282)\tLoss 0.0379 (0.9337)\tAcc@1 100.000 (78.048)\tAcc@5 100.000 (94.097)\n",
      "Test: [1410/2500]\tTime 0.508 (0.282)\tLoss 0.6589 (0.9320)\tAcc@1 80.000 (78.094)\tAcc@5 100.000 (94.103)\n",
      "Test: [1420/2500]\tTime 0.145 (0.282)\tLoss 0.5137 (0.9327)\tAcc@1 95.000 (78.072)\tAcc@5 100.000 (94.099)\n",
      "Test: [1430/2500]\tTime 0.777 (0.282)\tLoss 1.8422 (0.9314)\tAcc@1 50.000 (78.106)\tAcc@5 85.000 (94.102)\n",
      "Test: [1440/2500]\tTime 0.146 (0.281)\tLoss 0.0674 (0.9299)\tAcc@1 100.000 (78.161)\tAcc@5 100.000 (94.112)\n",
      "Test: [1450/2500]\tTime 0.851 (0.282)\tLoss 0.9030 (0.9308)\tAcc@1 80.000 (78.115)\tAcc@5 100.000 (94.125)\n",
      "Test: [1460/2500]\tTime 0.144 (0.281)\tLoss 2.6877 (0.9338)\tAcc@1 45.000 (78.080)\tAcc@5 70.000 (94.103)\n",
      "Test: [1470/2500]\tTime 0.742 (0.282)\tLoss 1.2398 (0.9400)\tAcc@1 75.000 (77.967)\tAcc@5 85.000 (94.018)\n",
      "Test: [1480/2500]\tTime 0.145 (0.282)\tLoss 0.8006 (0.9447)\tAcc@1 80.000 (77.893)\tAcc@5 90.000 (93.970)\n",
      "Test: [1490/2500]\tTime 0.658 (0.282)\tLoss 1.6393 (0.9434)\tAcc@1 65.000 (77.931)\tAcc@5 95.000 (93.997)\n",
      "Test: [1500/2500]\tTime 0.143 (0.282)\tLoss 2.4658 (0.9483)\tAcc@1 45.000 (77.835)\tAcc@5 80.000 (93.944)\n",
      "Test: [1510/2500]\tTime 0.146 (0.282)\tLoss 0.0382 (0.9519)\tAcc@1 100.000 (77.786)\tAcc@5 100.000 (93.891)\n",
      "Test: [1520/2500]\tTime 0.143 (0.282)\tLoss 1.1222 (0.9502)\tAcc@1 75.000 (77.840)\tAcc@5 90.000 (93.889)\n",
      "Test: [1530/2500]\tTime 0.144 (0.281)\tLoss 0.3933 (0.9504)\tAcc@1 95.000 (77.880)\tAcc@5 95.000 (93.880)\n",
      "Test: [1540/2500]\tTime 0.145 (0.281)\tLoss 1.6282 (0.9501)\tAcc@1 80.000 (77.914)\tAcc@5 85.000 (93.868)\n",
      "Test: [1550/2500]\tTime 0.142 (0.281)\tLoss 1.9547 (0.9557)\tAcc@1 10.000 (77.763)\tAcc@5 90.000 (93.804)\n",
      "Test: [1560/2500]\tTime 0.146 (0.281)\tLoss 1.2201 (0.9621)\tAcc@1 55.000 (77.588)\tAcc@5 90.000 (93.738)\n",
      "Test: [1570/2500]\tTime 0.150 (0.281)\tLoss 0.2987 (0.9628)\tAcc@1 95.000 (77.578)\tAcc@5 100.000 (93.714)\n",
      "Test: [1580/2500]\tTime 0.143 (0.280)\tLoss 2.0254 (0.9636)\tAcc@1 65.000 (77.552)\tAcc@5 65.000 (93.700)\n",
      "Test: [1590/2500]\tTime 0.142 (0.281)\tLoss 1.0228 (0.9710)\tAcc@1 80.000 (77.439)\tAcc@5 95.000 (93.589)\n",
      "Test: [1600/2500]\tTime 0.143 (0.280)\tLoss 0.2710 (0.9733)\tAcc@1 95.000 (77.286)\tAcc@5 100.000 (93.585)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [1610/2500]\tTime 0.144 (0.281)\tLoss 0.9247 (0.9737)\tAcc@1 85.000 (77.297)\tAcc@5 90.000 (93.575)\n",
      "Test: [1620/2500]\tTime 0.144 (0.281)\tLoss 1.8636 (0.9744)\tAcc@1 55.000 (77.310)\tAcc@5 80.000 (93.553)\n",
      "Test: [1630/2500]\tTime 0.151 (0.280)\tLoss 1.8643 (0.9797)\tAcc@1 65.000 (77.207)\tAcc@5 95.000 (93.495)\n",
      "Test: [1640/2500]\tTime 0.145 (0.280)\tLoss 2.2488 (0.9838)\tAcc@1 50.000 (77.142)\tAcc@5 90.000 (93.464)\n",
      "Test: [1650/2500]\tTime 0.145 (0.280)\tLoss 1.5935 (0.9870)\tAcc@1 70.000 (77.062)\tAcc@5 80.000 (93.428)\n",
      "Test: [1660/2500]\tTime 0.144 (0.280)\tLoss 2.0610 (0.9894)\tAcc@1 45.000 (76.987)\tAcc@5 85.000 (93.420)\n",
      "Test: [1670/2500]\tTime 0.147 (0.280)\tLoss 0.1695 (0.9921)\tAcc@1 95.000 (76.927)\tAcc@5 100.000 (93.408)\n",
      "Test: [1680/2500]\tTime 0.144 (0.280)\tLoss 0.4612 (0.9889)\tAcc@1 90.000 (77.002)\tAcc@5 95.000 (93.430)\n",
      "Test: [1690/2500]\tTime 0.578 (0.280)\tLoss 2.6558 (0.9929)\tAcc@1 55.000 (76.904)\tAcc@5 80.000 (93.400)\n",
      "Test: [1700/2500]\tTime 0.144 (0.280)\tLoss 0.9887 (0.9967)\tAcc@1 75.000 (76.869)\tAcc@5 95.000 (93.339)\n",
      "Test: [1710/2500]\tTime 0.748 (0.280)\tLoss 0.9828 (0.9993)\tAcc@1 80.000 (76.818)\tAcc@5 90.000 (93.323)\n",
      "Test: [1720/2500]\tTime 0.142 (0.280)\tLoss 0.0487 (0.9975)\tAcc@1 100.000 (76.871)\tAcc@5 100.000 (93.335)\n",
      "Test: [1730/2500]\tTime 0.303 (0.280)\tLoss 1.8676 (1.0005)\tAcc@1 60.000 (76.794)\tAcc@5 75.000 (93.310)\n",
      "Test: [1740/2500]\tTime 0.144 (0.279)\tLoss 2.2371 (1.0017)\tAcc@1 65.000 (76.778)\tAcc@5 80.000 (93.294)\n",
      "Test: [1750/2500]\tTime 0.771 (0.279)\tLoss 1.2523 (1.0018)\tAcc@1 75.000 (76.765)\tAcc@5 90.000 (93.307)\n",
      "Test: [1760/2500]\tTime 0.143 (0.280)\tLoss 0.5229 (1.0019)\tAcc@1 90.000 (76.777)\tAcc@5 100.000 (93.311)\n",
      "Test: [1770/2500]\tTime 0.875 (0.280)\tLoss 1.5020 (1.0041)\tAcc@1 65.000 (76.736)\tAcc@5 85.000 (93.289)\n",
      "Test: [1780/2500]\tTime 0.143 (0.279)\tLoss 2.2960 (1.0070)\tAcc@1 60.000 (76.673)\tAcc@5 75.000 (93.265)\n",
      "Test: [1790/2500]\tTime 0.598 (0.280)\tLoss 1.2467 (1.0070)\tAcc@1 90.000 (76.700)\tAcc@5 95.000 (93.261)\n",
      "Test: [1800/2500]\tTime 0.143 (0.280)\tLoss 0.8552 (1.0073)\tAcc@1 85.000 (76.691)\tAcc@5 100.000 (93.259)\n",
      "Test: [1810/2500]\tTime 0.893 (0.280)\tLoss 0.8594 (1.0071)\tAcc@1 90.000 (76.717)\tAcc@5 95.000 (93.250)\n",
      "Test: [1820/2500]\tTime 0.142 (0.280)\tLoss 4.8790 (1.0088)\tAcc@1 40.000 (76.697)\tAcc@5 55.000 (93.229)\n",
      "Test: [1830/2500]\tTime 0.584 (0.280)\tLoss 1.1587 (1.0138)\tAcc@1 75.000 (76.622)\tAcc@5 90.000 (93.162)\n",
      "Test: [1840/2500]\tTime 0.144 (0.280)\tLoss 1.0285 (1.0158)\tAcc@1 80.000 (76.562)\tAcc@5 85.000 (93.129)\n",
      "Test: [1850/2500]\tTime 0.515 (0.280)\tLoss 2.7467 (1.0162)\tAcc@1 40.000 (76.564)\tAcc@5 70.000 (93.117)\n",
      "Test: [1860/2500]\tTime 0.142 (0.280)\tLoss 1.3058 (1.0201)\tAcc@1 40.000 (76.454)\tAcc@5 95.000 (93.066)\n",
      "Test: [1870/2500]\tTime 0.822 (0.280)\tLoss 1.4175 (1.0219)\tAcc@1 55.000 (76.384)\tAcc@5 90.000 (93.038)\n",
      "Test: [1880/2500]\tTime 0.143 (0.280)\tLoss 0.8496 (1.0239)\tAcc@1 80.000 (76.342)\tAcc@5 95.000 (93.014)\n",
      "Test: [1890/2500]\tTime 0.979 (0.280)\tLoss 0.5726 (1.0240)\tAcc@1 80.000 (76.348)\tAcc@5 100.000 (93.014)\n",
      "Test: [1900/2500]\tTime 0.143 (0.280)\tLoss 1.0799 (1.0253)\tAcc@1 85.000 (76.336)\tAcc@5 90.000 (92.993)\n",
      "Test: [1910/2500]\tTime 0.529 (0.280)\tLoss 2.3680 (1.0283)\tAcc@1 40.000 (76.277)\tAcc@5 85.000 (92.962)\n",
      "Test: [1920/2500]\tTime 0.144 (0.280)\tLoss 1.1816 (1.0302)\tAcc@1 80.000 (76.249)\tAcc@5 85.000 (92.936)\n",
      "Test: [1930/2500]\tTime 0.669 (0.280)\tLoss 1.9725 (1.0299)\tAcc@1 65.000 (76.284)\tAcc@5 75.000 (92.926)\n",
      "Test: [1940/2500]\tTime 0.143 (0.280)\tLoss 1.0732 (1.0330)\tAcc@1 75.000 (76.231)\tAcc@5 80.000 (92.883)\n",
      "Test: [1950/2500]\tTime 0.227 (0.280)\tLoss 0.6268 (1.0330)\tAcc@1 80.000 (76.233)\tAcc@5 100.000 (92.881)\n",
      "Test: [1960/2500]\tTime 0.144 (0.280)\tLoss 3.6037 (1.0344)\tAcc@1 30.000 (76.158)\tAcc@5 45.000 (92.853)\n",
      "Test: [1970/2500]\tTime 0.577 (0.280)\tLoss 0.3671 (1.0369)\tAcc@1 95.000 (76.144)\tAcc@5 100.000 (92.826)\n",
      "Test: [1980/2500]\tTime 0.142 (0.280)\tLoss 2.1152 (1.0376)\tAcc@1 65.000 (76.136)\tAcc@5 85.000 (92.819)\n",
      "Test: [1990/2500]\tTime 0.695 (0.280)\tLoss 1.6154 (1.0395)\tAcc@1 65.000 (76.113)\tAcc@5 90.000 (92.788)\n",
      "Test: [2000/2500]\tTime 0.143 (0.280)\tLoss 0.3850 (1.0428)\tAcc@1 90.000 (76.062)\tAcc@5 100.000 (92.756)\n",
      "Test: [2010/2500]\tTime 0.683 (0.280)\tLoss 1.4329 (1.0398)\tAcc@1 65.000 (76.139)\tAcc@5 90.000 (92.785)\n",
      "Test: [2020/2500]\tTime 0.144 (0.280)\tLoss 1.3270 (1.0413)\tAcc@1 60.000 (76.128)\tAcc@5 90.000 (92.756)\n",
      "Test: [2030/2500]\tTime 0.312 (0.280)\tLoss 0.4246 (1.0445)\tAcc@1 95.000 (76.036)\tAcc@5 95.000 (92.725)\n",
      "Test: [2040/2500]\tTime 0.145 (0.280)\tLoss 0.5912 (1.0456)\tAcc@1 90.000 (76.002)\tAcc@5 100.000 (92.714)\n",
      "Test: [2050/2500]\tTime 0.564 (0.280)\tLoss 0.2867 (1.0487)\tAcc@1 95.000 (75.922)\tAcc@5 100.000 (92.689)\n",
      "Test: [2060/2500]\tTime 0.145 (0.280)\tLoss 1.2045 (1.0475)\tAcc@1 70.000 (75.956)\tAcc@5 95.000 (92.693)\n",
      "Test: [2070/2500]\tTime 0.740 (0.281)\tLoss 1.7474 (1.0509)\tAcc@1 70.000 (75.893)\tAcc@5 85.000 (92.670)\n",
      "Test: [2080/2500]\tTime 0.142 (0.281)\tLoss 0.4223 (1.0514)\tAcc@1 95.000 (75.899)\tAcc@5 95.000 (92.653)\n",
      "Test: [2090/2500]\tTime 0.731 (0.281)\tLoss 3.0931 (1.0530)\tAcc@1 15.000 (75.858)\tAcc@5 60.000 (92.621)\n",
      "Test: [2100/2500]\tTime 0.144 (0.281)\tLoss 0.8764 (1.0595)\tAcc@1 75.000 (75.702)\tAcc@5 90.000 (92.544)\n",
      "Test: [2110/2500]\tTime 0.477 (0.281)\tLoss 0.8566 (1.0613)\tAcc@1 95.000 (75.658)\tAcc@5 95.000 (92.527)\n",
      "Test: [2120/2500]\tTime 0.142 (0.281)\tLoss 1.5205 (1.0634)\tAcc@1 50.000 (75.599)\tAcc@5 100.000 (92.508)\n",
      "Test: [2130/2500]\tTime 0.849 (0.281)\tLoss 1.2749 (1.0640)\tAcc@1 75.000 (75.577)\tAcc@5 90.000 (92.513)\n",
      "Test: [2140/2500]\tTime 0.143 (0.281)\tLoss 1.2560 (1.0642)\tAcc@1 55.000 (75.589)\tAcc@5 95.000 (92.508)\n",
      "Test: [2150/2500]\tTime 0.835 (0.281)\tLoss 2.9453 (1.0668)\tAcc@1 35.000 (75.530)\tAcc@5 65.000 (92.469)\n",
      "Test: [2160/2500]\tTime 0.144 (0.281)\tLoss 1.0381 (1.0669)\tAcc@1 80.000 (75.525)\tAcc@5 90.000 (92.469)\n",
      "Test: [2170/2500]\tTime 0.580 (0.281)\tLoss 2.4231 (1.0676)\tAcc@1 55.000 (75.516)\tAcc@5 70.000 (92.469)\n",
      "Test: [2180/2500]\tTime 0.144 (0.281)\tLoss 1.7927 (1.0688)\tAcc@1 55.000 (75.481)\tAcc@5 85.000 (92.458)\n",
      "Test: [2190/2500]\tTime 0.505 (0.280)\tLoss 2.1618 (1.0675)\tAcc@1 35.000 (75.502)\tAcc@5 80.000 (92.467)\n",
      "Test: [2200/2500]\tTime 0.146 (0.280)\tLoss 0.7144 (1.0684)\tAcc@1 85.000 (75.473)\tAcc@5 95.000 (92.456)\n",
      "Test: [2210/2500]\tTime 0.494 (0.280)\tLoss 0.5349 (1.0692)\tAcc@1 85.000 (75.466)\tAcc@5 100.000 (92.445)\n",
      "Test: [2220/2500]\tTime 0.143 (0.280)\tLoss 0.8486 (1.0736)\tAcc@1 80.000 (75.378)\tAcc@5 90.000 (92.398)\n",
      "Test: [2230/2500]\tTime 0.654 (0.280)\tLoss 1.5973 (1.0733)\tAcc@1 70.000 (75.399)\tAcc@5 85.000 (92.400)\n",
      "Test: [2240/2500]\tTime 0.145 (0.280)\tLoss 0.8440 (1.0734)\tAcc@1 70.000 (75.382)\tAcc@5 95.000 (92.403)\n",
      "Test: [2250/2500]\tTime 0.520 (0.280)\tLoss 0.2633 (1.0756)\tAcc@1 95.000 (75.338)\tAcc@5 95.000 (92.388)\n",
      "Test: [2260/2500]\tTime 0.144 (0.280)\tLoss 2.0989 (1.0764)\tAcc@1 65.000 (75.332)\tAcc@5 75.000 (92.368)\n",
      "Test: [2270/2500]\tTime 0.146 (0.280)\tLoss 1.4934 (1.0813)\tAcc@1 55.000 (75.218)\tAcc@5 95.000 (92.318)\n",
      "Test: [2280/2500]\tTime 0.142 (0.280)\tLoss 0.7912 (1.0849)\tAcc@1 75.000 (75.114)\tAcc@5 100.000 (92.310)\n",
      "Test: [2290/2500]\tTime 0.277 (0.280)\tLoss 0.1971 (1.0831)\tAcc@1 95.000 (75.155)\tAcc@5 100.000 (92.331)\n",
      "Test: [2300/2500]\tTime 0.145 (0.280)\tLoss 1.7390 (1.0832)\tAcc@1 80.000 (75.176)\tAcc@5 95.000 (92.336)\n",
      "Test: [2310/2500]\tTime 0.189 (0.280)\tLoss 0.7742 (1.0841)\tAcc@1 75.000 (75.156)\tAcc@5 100.000 (92.339)\n",
      "Test: [2320/2500]\tTime 0.144 (0.280)\tLoss 1.0973 (1.0832)\tAcc@1 65.000 (75.172)\tAcc@5 100.000 (92.361)\n",
      "Test: [2330/2500]\tTime 0.146 (0.280)\tLoss 1.6451 (1.0851)\tAcc@1 65.000 (75.133)\tAcc@5 75.000 (92.338)\n",
      "Test: [2340/2500]\tTime 0.145 (0.280)\tLoss 0.0984 (1.0837)\tAcc@1 100.000 (75.162)\tAcc@5 100.000 (92.345)\n",
      "Test: [2350/2500]\tTime 0.171 (0.280)\tLoss 0.7907 (1.0816)\tAcc@1 70.000 (75.191)\tAcc@5 100.000 (92.369)\n",
      "Test: [2360/2500]\tTime 0.141 (0.280)\tLoss 0.9820 (1.0810)\tAcc@1 75.000 (75.201)\tAcc@5 95.000 (92.378)\n",
      "Test: [2370/2500]\tTime 0.146 (0.280)\tLoss 0.3640 (1.0800)\tAcc@1 90.000 (75.205)\tAcc@5 100.000 (92.402)\n",
      "Test: [2380/2500]\tTime 0.143 (0.280)\tLoss 1.1680 (1.0790)\tAcc@1 80.000 (75.220)\tAcc@5 100.000 (92.415)\n",
      "Test: [2390/2500]\tTime 0.148 (0.280)\tLoss 0.1302 (1.0763)\tAcc@1 100.000 (75.289)\tAcc@5 100.000 (92.440)\n",
      "Test: [2400/2500]\tTime 0.143 (0.280)\tLoss 1.0452 (1.0743)\tAcc@1 70.000 (75.335)\tAcc@5 95.000 (92.455)\n",
      "Test: [2410/2500]\tTime 0.145 (0.280)\tLoss 1.3948 (1.0776)\tAcc@1 70.000 (75.280)\tAcc@5 80.000 (92.422)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [2420/2500]\tTime 0.144 (0.280)\tLoss 2.5110 (1.0788)\tAcc@1 35.000 (75.242)\tAcc@5 80.000 (92.414)\n",
      "Test: [2430/2500]\tTime 0.145 (0.280)\tLoss 1.2495 (1.0815)\tAcc@1 55.000 (75.169)\tAcc@5 100.000 (92.392)\n",
      "Test: [2440/2500]\tTime 0.145 (0.280)\tLoss 1.1586 (1.0818)\tAcc@1 60.000 (75.158)\tAcc@5 95.000 (92.399)\n",
      "Test: [2450/2500]\tTime 0.143 (0.279)\tLoss 0.4271 (1.0836)\tAcc@1 90.000 (75.100)\tAcc@5 95.000 (92.391)\n",
      "Test: [2460/2500]\tTime 0.142 (0.279)\tLoss 0.1269 (1.0833)\tAcc@1 100.000 (75.116)\tAcc@5 100.000 (92.389)\n",
      "Test: [2470/2500]\tTime 0.145 (0.279)\tLoss 0.3178 (1.0807)\tAcc@1 90.000 (75.152)\tAcc@5 95.000 (92.406)\n",
      "Test: [2480/2500]\tTime 0.143 (0.279)\tLoss 1.1036 (1.0775)\tAcc@1 90.000 (75.238)\tAcc@5 90.000 (92.432)\n",
      "Test: [2490/2500]\tTime 0.145 (0.280)\tLoss 0.8320 (1.0749)\tAcc@1 85.000 (75.303)\tAcc@5 95.000 (92.453)\n",
      " * Acc@1 75.256 Acc@5 92.440\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(75.256, 92.44)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale = 0.875\n",
    "print(\"=> using pre-trained parameters '{}'\".format('imagenet'))\n",
    "a1 = 0.4657\n",
    "model_1 = pretrainedmodels.__dict__['vgg19'](num_classes=1000,pretrained='imagenet')\n",
    "a2 = 0.5343\n",
    "model_2 = pretrainedmodels.__dict__['vgg19_bn'](num_classes=1000,pretrained='imagenet')\n",
    "\n",
    "print('Images transformed from size {} to {}'.format(\n",
    "    int(round(max(model_1.input_size) / scale)),\n",
    "    model_1.input_size))\n",
    "\n",
    "val_tf_1 = pretrainedmodels.utils.TransformImage(\n",
    "    model_1,\n",
    "    scale=scale,\n",
    "    preserve_aspect_ratio=True\n",
    ")\n",
    "\n",
    "val_tf_2 = pretrainedmodels.utils.TransformImage(\n",
    "    model_2,\n",
    "    scale=scale,\n",
    "    preserve_aspect_ratio=True\n",
    ")\n",
    "\n",
    "val_loader_1 = torch.utils.data.DataLoader(\n",
    "    datasets.ImageFolder(valdir, val_tf_1),\n",
    "    batch_size=20, shuffle=False,\n",
    "    num_workers=4, pin_memory=True)\n",
    "\n",
    "val_loader_2 = torch.utils.data.DataLoader(\n",
    "    datasets.ImageFolder(valdir, val_tf_2),\n",
    "    batch_size=20, shuffle=False,\n",
    "    num_workers=4, pin_memory=True)\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "model_1 = torch.nn.DataParallel(model_1).cuda()\n",
    "model_2 = torch.nn.DataParallel(model_2).cuda()\n",
    "validate_2(val_loader_1,val_loader_2, a1, model_1, a2, model_2, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
